---
title: Precalc Summary
description: This is a collection of precalculus concepts.
slug: 20240621-precalc
lang: en
date: 2024-06-21
type: Post
tags:
  - math
---

_This isn't completely related to computer science so I didn't include the tag :P. Functions in this article only have
single variables._

## Limit

```math
\lim_{x \rightarrow a^{+}}{f(x)} = b
```

represents the fact that when $x$ approaches $a$ from right, $f$ approaches $b$, which is called a "right limit".

```math
\lim_{x \rightarrow a^{-}}{f(x)} = b
```

represents the fact that when $x$ approaches $a$ from left, $f$ approaches $b$, which is called a "left limit".
When both of them are the same, that is

```math
\lim_{x \rightarrow a^{+}}{f(x)} = \lim_{x \rightarrow a^{-}}{f(x)} = b
```

, we say that when $x$ approaches $a$, $f$ approaches $b$, which is

```math
\lim_{x \rightarrow a}{f(x)} = b
```

, this also shows that $f$ has a limit at $x=a$.

## Continuity

For a function to be continuous in a certain interval, it must first have limit in that interval. If $f: R \rightarrow R, f(x)$ is
continuous given $x \in [a,b]$, then it must satisfy the following facts:

1. For all $c$ in $[a,b]$, $f$ at $x=c$ must have a limit that is defined.
2. For all $c$ in $[a,b]$, $f(c) = \lim_{x \rightarrow c}{f(x)}$

## Derivative

A function's derivative with respect to a specific variable is the function's change regarding the change of the specified variable.
For example, the derivative of $f: R \rightarrow R, f(x)$ regarding $x$ is $\frac{df}{dx}$.
It can be defined like this:

```math
\frac{df}{dx} = \lim_{h \rightarrow 0}{\frac{f(x+h) - f(x)}{h}}
```

## Differentiable

When a function is differentiable in a certain interval, it must first be continuous in that interval. If $f: R \rightarrow R, f(x)$
is differentiable, then its derivative must be continuous, so finally we can say that

```math
\text{Differentiable} \implies \text{Continuous} \implies \text{Limit Existing}
```

## IVT Intermediate Value Theorem

For a continuous function $f$ in interval $[a,b]$, it must satisfy the following fact: $\forall c \in [\min(f(a), f(b)), \max(f(a), f(b)) ]$,
there exists at least one $r$ that fulfills $f(r) = c \{r \in [a,b]\}$.

## Boundedness Theorem

For a function $f$ in interval $[a,b]$, $U$ denotes the set of upper bounds (scalar) and $L$ denotes the set of lower bounds (scalar).
Define $v, \forall v \in [a, b]$,

```math
l \leq f(v) \leq u, l \in L, u \in U
```

## EVT Extreme Value Theorem

When we limit the upper bound set and the lower bound set to only include values that exist as $f$'s output, we get EVT,
where $L$ and $U$ are each reduced respectively to a single value, $f(c)$ and $f(d)$.

## Exponential Differentiation

Let $e$ be a number, $b$ be a constant scalar, that results in

```math
f(x) = e^{bx} \\
\frac{df}{dx} = be^{bx} = b \cdot f(x)
```

, we can say that for all $a \in R, a > 0$,

```math
f(x) = a^x = e^{\ln(a)x} \\
\frac{df}{dx} = \ln(a) \cdot e^{\ln(a)x} = \ln(a) \cdot f(x)
```

## Logarithmic Differentiation

We know that

```math
\frac{d(\ln x)}{dx} = \frac{1}{x}
```

,
so for function $f$,

```math
\frac{d(\ln f(x))}{dx} = \frac{d(\ln f(x))}{df} \cdot \frac{df}{dx} = \frac{1}{f(x)} \cdot \frac{df}{dx}
```

. The above technique is actually chain rule if you look closely!

## Linear Approximation

Given function $f(x)$, the linear approximation (tangent lines) at
$(r, f(r))$ is $y = f'(r)(x-r)+f(r) = g(x)$.
($f'$ is the derivative of $f$)

### Cheatsheet

```math
(1+x)^r \approx 1 + rx \text{ where } x \rightarrow 0
```

```math
\sin(x) \approx x \text{ where } x \rightarrow 0
```

```math
\cos(x) \approx 1 \text{ where } x \rightarrow 0
```

```math
e^x \approx 1 + x \text{ where } x \rightarrow 0
```

```math
\ln(1+x) \approx x \text{ where } x \rightarrow 0
```

### Deduction

```math
(1+x)^r \approx (1+0)^r + r(1+0)^{r-1}x=1+rx
```

```math
\sin(x)\approx \sin(0) + \cos(0)x = x
```

```math
\cos(x)\approx \cos(0) + -\sin(0)x = 1
```

```math
e^x \approx e^0 + e^0 x = 1 + x
```

```math
\ln(1+x) \approx \ln(1) + \frac{x}{1+0}=x
```

## Quadratic Approximation

Think of a function $f(x)=ax^2+bx+c$, we want to see its derivatives at $x=0$:

```math
f(0)=c,
f'(0)=b,
f''(0)=2a
```

which can represent $f(x)$ as $f(0) + f'(0)x + f''(0)x^2 \cdot (2!)^{-1}$.
Generalizing this observation, we can get that the quadratic approximation at $x=r$ is

```math
f(x) \approx f(r) + \frac{f'(r)(x-r)^1}{1!} +
\frac{f''(r)(x-r)^2}{2!}
```

The notation for quadratic approximation of function $f$ is $Q(f)$.

## Approximation Laws

```math
Q(f(x) \cdot g(x)) = Q(Q(f(x))\cdot Q(g(x)))
```

## Taylor Series

It's not particularly difficult to see the pattern from above approximations. For function $f$, its
approximation at $x=r$ would be

```math
f(x) = f(r) + \sum^{\infty }_{n=1}{\frac{f^{(n)}(x) \cdot (x-r)^n}{n!}}
```

, which is called Taylor series.
